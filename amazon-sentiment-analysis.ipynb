{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport bz2, string, re, gc\n\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk.stem import SnowballStemmer, WordNetLemmatizer\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom tqdm.auto import tqdm\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\n\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn \nimport torch.optim as optim\nimport torch\nfrom transformers import AutoConfig, AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n\nnp.random.seed(42)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-09T18:29:40.822885Z","iopub.execute_input":"2022-01-09T18:29:40.823424Z","iopub.status.idle":"2022-01-09T18:29:48.039074Z","shell.execute_reply.started":"2022-01-09T18:29:40.823310Z","shell.execute_reply":"2022-01-09T18:29:48.038181Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"#Device selection\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(f'Using {device} device')","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:29:48.042052Z","iopub.execute_input":"2022-01-09T18:29:48.042309Z","iopub.status.idle":"2022-01-09T18:29:48.088807Z","shell.execute_reply.started":"2022-01-09T18:29:48.042284Z","shell.execute_reply":"2022-01-09T18:29:48.087670Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Reading the files as bz2 extensions","metadata":{}},{"cell_type":"code","source":"trainFileB = bz2.BZ2File('../input/amazonreviews/train.ft.txt.bz2')\ntestFileB = bz2.BZ2File('../input/amazonreviews/test.ft.txt.bz2')\ntrainFile = trainFileB.readlines()\ntestFile = testFileB.readlines()\ntrainFileB.close()\ntestFileB.close()\ndel trainFileB, testFileB","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:29:48.092327Z","iopub.execute_input":"2022-01-09T18:29:48.092581Z","iopub.status.idle":"2022-01-09T18:31:30.356042Z","shell.execute_reply.started":"2022-01-09T18:29:48.092556Z","shell.execute_reply":"2022-01-09T18:31:30.355155Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:31:30.357574Z","iopub.execute_input":"2022-01-09T18:31:30.357924Z","iopub.status.idle":"2022-01-09T18:31:30.681053Z","shell.execute_reply.started":"2022-01-09T18:31:30.357889Z","shell.execute_reply":"2022-01-09T18:31:30.680077Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print('train data {}'.format(len(trainFile)))\nprint('test data {}'.format(len(testFile)))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:31:30.682504Z","iopub.execute_input":"2022-01-09T18:31:30.683159Z","iopub.status.idle":"2022-01-09T18:31:30.689600Z","shell.execute_reply.started":"2022-01-09T18:31:30.683115Z","shell.execute_reply":"2022-01-09T18:31:30.688673Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Only select the 5% of the data since the huge dataset","metadata":{}},{"cell_type":"code","source":"trainFile = trainFile[:int(len(trainFile)*0.1)]\ntestFile = testFile[:int(len(testFile)*0.1)]","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:31:30.691110Z","iopub.execute_input":"2022-01-09T18:31:30.691842Z","iopub.status.idle":"2022-01-09T18:31:30.986144Z","shell.execute_reply.started":"2022-01-09T18:31:30.691797Z","shell.execute_reply":"2022-01-09T18:31:30.985058Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print('train data {}'.format(len(trainFile)))\nprint('test data {}'.format(len(testFile)))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:31:30.987541Z","iopub.execute_input":"2022-01-09T18:31:30.988060Z","iopub.status.idle":"2022-01-09T18:31:30.999091Z","shell.execute_reply.started":"2022-01-09T18:31:30.988006Z","shell.execute_reply":"2022-01-09T18:31:30.998210Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Helper functions\n\nThese functions are used in order to clean most of the texts. We remove special characters, Urls, stopwords in english and then we could also include lemmization or stemming.","metadata":{}},{"cell_type":"code","source":"#Cleaning and Stemming part\n\ndef removePunctuation(text):\n    return re.sub(r'['+string.punctuation+']',' ',text)\n\ndef removeUrl(text):\n    return re.sub(r'http(s?)\\S+',' ',text)\n\ndef removeStopWords(text):\n    text = text.split()\n    words = stopwords.words('english')\n    for i,w in enumerate(text):\n        if w in words:\n            text[i] = ''\n    return ' '.join(text)\n\ndef lemmization(text):\n    lemmatizer = WordNetLemmatizer()\n    text = ' '.join(lemmatizer.lemmatize(w, wordnet.synsets(w)[0].pos()) for w in text.split() if len(wordnet.synsets(w))>0) \n    return text\n\ndef stemming(text):\n    stemmer = SnowballStemmer('english')\n    text = ' '.join(stemmer.stem(w) for w in text.split())\n    return text\n            \ndef cleanText(text):\n    text = text.lower()\n    text = removeUrl(text)\n    text = removePunctuation(text)\n    text = removeStopWords(text)\n#     text = stemming(text)\n#     text = lemmization(text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:31:31.002273Z","iopub.execute_input":"2022-01-09T18:31:31.002894Z","iopub.status.idle":"2022-01-09T18:31:31.025961Z","shell.execute_reply.started":"2022-01-09T18:31:31.002855Z","shell.execute_reply":"2022-01-09T18:31:31.024916Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Creating the dataframes to be used later in the Torch Datasets. The texts are parsed, then a map is used to clean the text","metadata":{}},{"cell_type":"code","source":"def parseInput(text):\n    text = text.decode('utf-8')\n    text = text.split(maxsplit=1)\n    label = int(text[0][-1]) - 1\n    data = text[1]\n    return data, label\n\ntrainData = pd.DataFrame(trainFile)\ntestData = pd.DataFrame(testFile)\n\ntrainData['text'], trainData['target'] = zip(*trainData[0].map(parseInput))\ntestData['text'], testData['target'] = zip(*testData[0].map(parseInput))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:31:31.027995Z","iopub.execute_input":"2022-01-09T18:31:31.028468Z","iopub.status.idle":"2022-01-09T18:31:33.405418Z","shell.execute_reply.started":"2022-01-09T18:31:31.028427Z","shell.execute_reply":"2022-01-09T18:31:33.404572Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"trainData.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:31:33.408361Z","iopub.execute_input":"2022-01-09T18:31:33.408629Z","iopub.status.idle":"2022-01-09T18:31:33.425473Z","shell.execute_reply.started":"2022-01-09T18:31:33.408603Z","shell.execute_reply":"2022-01-09T18:31:33.424538Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"del trainFile\ndel testFile","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:31:33.427044Z","iopub.execute_input":"2022-01-09T18:31:33.427725Z","iopub.status.idle":"2022-01-09T18:31:33.438457Z","shell.execute_reply.started":"2022-01-09T18:31:33.427684Z","shell.execute_reply":"2022-01-09T18:31:33.437678Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:31:33.441324Z","iopub.execute_input":"2022-01-09T18:31:33.441607Z","iopub.status.idle":"2022-01-09T18:31:33.617707Z","shell.execute_reply.started":"2022-01-09T18:31:33.441580Z","shell.execute_reply":"2022-01-09T18:31:33.616753Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"trainData['text'] = trainData['text'].map(cleanText)\ntestData['text'] = testData['text'].map(cleanText)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:31:33.619264Z","iopub.execute_input":"2022-01-09T18:31:33.619700Z","iopub.status.idle":"2022-01-09T18:33:30.922689Z","shell.execute_reply.started":"2022-01-09T18:31:33.619599Z","shell.execute_reply":"2022-01-09T18:33:30.921812Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"trainData.drop(columns=[0], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:33:30.923923Z","iopub.execute_input":"2022-01-09T18:33:30.924246Z","iopub.status.idle":"2022-01-09T18:33:30.981215Z","shell.execute_reply.started":"2022-01-09T18:33:30.924212Z","shell.execute_reply":"2022-01-09T18:33:30.980345Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"trainData.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:33:30.982497Z","iopub.execute_input":"2022-01-09T18:33:30.982925Z","iopub.status.idle":"2022-01-09T18:33:31.544276Z","shell.execute_reply.started":"2022-01-09T18:33:30.982881Z","shell.execute_reply":"2022-01-09T18:33:31.543408Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"trainData.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:33:31.545673Z","iopub.execute_input":"2022-01-09T18:33:31.546033Z","iopub.status.idle":"2022-01-09T18:33:31.554716Z","shell.execute_reply.started":"2022-01-09T18:33:31.545996Z","shell.execute_reply":"2022-01-09T18:33:31.553742Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"trainData, validData = train_test_split(trainData, train_size=0.8, random_state = 42, stratify = trainData['target'])\ntrainData.reset_index(drop=True, inplace=True)\nvalidData.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:33:31.556310Z","iopub.execute_input":"2022-01-09T18:33:31.556700Z","iopub.status.idle":"2022-01-09T18:33:31.814707Z","shell.execute_reply.started":"2022-01-09T18:33:31.556662Z","shell.execute_reply":"2022-01-09T18:33:31.813857Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Small EDA: showing the length distributions of tokenized texts and the labels distrubution","metadata":{}},{"cell_type":"code","source":"sns.lineplot(data=trainData.sort_values(by='text', \n                                        key=lambda x : x.str.split().str.len(),\n                                        ignore_index = True).text.str.split().str.len())","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:33:31.815965Z","iopub.execute_input":"2022-01-09T18:33:31.816290Z","iopub.status.idle":"2022-01-09T18:33:52.081692Z","shell.execute_reply.started":"2022-01-09T18:33:31.816256Z","shell.execute_reply":"2022-01-09T18:33:52.080078Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"sns.kdeplot(trainData['text'].str.split().str.len(), fill=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:33:52.082996Z","iopub.execute_input":"2022-01-09T18:33:52.083351Z","iopub.status.idle":"2022-01-09T18:33:56.141397Z","shell.execute_reply.started":"2022-01-09T18:33:52.083315Z","shell.execute_reply":"2022-01-09T18:33:56.140538Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x=trainData['target'])","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:33:56.142768Z","iopub.execute_input":"2022-01-09T18:33:56.143303Z","iopub.status.idle":"2022-01-09T18:33:56.274351Z","shell.execute_reply.started":"2022-01-09T18:33:56.143261Z","shell.execute_reply":"2022-01-09T18:33:56.273462Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression with Tf-Idf Vectorizer","metadata":{}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(max_features = 1500, \n                             stop_words = 'english', \n                             ngram_range = (1,3))\n\nX = vectorizer.fit_transform(trainData['text'])\nX_valid = vectorizer.transform(validData['text'])\ny = trainData['target']\ny_valid = validData['target']","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:33:56.275589Z","iopub.execute_input":"2022-01-09T18:33:56.276092Z","iopub.status.idle":"2022-01-09T18:36:09.562107Z","shell.execute_reply.started":"2022-01-09T18:33:56.276051Z","shell.execute_reply":"2022-01-09T18:36:09.561270Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"lr_model = LogisticRegression()\nlr_model.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:36:09.563326Z","iopub.execute_input":"2022-01-09T18:36:09.563677Z","iopub.status.idle":"2022-01-09T18:36:14.233474Z","shell.execute_reply.started":"2022-01-09T18:36:09.563625Z","shell.execute_reply":"2022-01-09T18:36:14.232544Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"y_pred = lr_model.predict(X)\ny_pred_valid = lr_model.predict(X_valid)\nconf_mat = confusion_matrix(y, y_pred)\nconf_mat_valid = confusion_matrix(y_valid, y_pred_valid)\nfig, ax = plt.subplots(1,2, figsize=(15,5))\nsns.heatmap(conf_mat, annot=True, cmap = 'Blues', ax=ax[0])\nax[0].set_title('Training Confusion Matrix')\nsns.heatmap(conf_mat_valid, annot=True, cmap = 'Blues', ax=ax[1])\nax[1].set_title('Validation Confusion Matrix')","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:36:14.237031Z","iopub.execute_input":"2022-01-09T18:36:14.237301Z","iopub.status.idle":"2022-01-09T18:36:15.103222Z","shell.execute_reply.started":"2022-01-09T18:36:14.237276Z","shell.execute_reply":"2022-01-09T18:36:15.102401Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"tot_sum = np.sum(conf_mat.ravel())\naccuracy = (conf_mat[0][0] + conf_mat[1][1]) / tot_sum\nrecall = (conf_mat[0][0])/(conf_mat[0][0] + conf_mat[0][1])\nprecision = (conf_mat[0][0])/(conf_mat[0][0] + conf_mat[1][0])\nf1_score = 2*precision*recall / (precision + recall)\nprint(f'Training scores: {accuracy:.2f} - {precision:.2f} - {recall:.2f} - {f1_score:.2f}')","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:36:15.104948Z","iopub.execute_input":"2022-01-09T18:36:15.105452Z","iopub.status.idle":"2022-01-09T18:36:15.112868Z","shell.execute_reply.started":"2022-01-09T18:36:15.105411Z","shell.execute_reply":"2022-01-09T18:36:15.112024Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### Creating the Datasets","metadata":{}},{"cell_type":"code","source":"class CustomDataset():\n    \n    def __init__(self, df, model='distilbert-base-uncased', max_len = 100, test = False):\n        self.df = df.sort_values(by='text', \n                                 key=lambda x : x.str.split().str.len(),\n                                 ignore_index = True)\n        self.max_len = max_len\n        self.tokenizer = AutoTokenizer.from_pretrained(model)\n        self.test = test\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        text = self.df['text'][idx]\n        label = self.df['target'][idx] if not self.test else None\n        tokenized_text = self.tokenizer.encode_plus(text,\n                                                    max_length=self.max_len,\n                                                    padding=False,\n                                                    truncation=True,\n                                                    add_special_tokens=True,\n                                                    return_tensors='pt')\n        \n        return {'input_ids': tokenized_text['input_ids'].squeeze(),\n                'attention_mask': tokenized_text['attention_mask'],\n                'target': torch.tensor(label, dtype=torch.float)}\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:36:15.114199Z","iopub.execute_input":"2022-01-09T18:36:15.114560Z","iopub.status.idle":"2022-01-09T18:36:15.124056Z","shell.execute_reply.started":"2022-01-09T18:36:15.114521Z","shell.execute_reply":"2022-01-09T18:36:15.123092Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"trainDataset = CustomDataset(trainData)\nvalidDataset = CustomDataset(validData)\ntestDataset = CustomDataset(testData)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:36:15.125163Z","iopub.execute_input":"2022-01-09T18:36:15.125919Z","iopub.status.idle":"2022-01-09T18:36:24.456507Z","shell.execute_reply.started":"2022-01-09T18:36:15.125881Z","shell.execute_reply":"2022-01-09T18:36:24.455661Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"trainDataset[0]","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:36:24.457884Z","iopub.execute_input":"2022-01-09T18:36:24.458234Z","iopub.status.idle":"2022-01-09T18:36:24.522361Z","shell.execute_reply.started":"2022-01-09T18:36:24.458197Z","shell.execute_reply":"2022-01-09T18:36:24.521505Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:36:24.523611Z","iopub.execute_input":"2022-01-09T18:36:24.524101Z","iopub.status.idle":"2022-01-09T18:36:25.796745Z","shell.execute_reply.started":"2022-01-09T18:36:24.524058Z","shell.execute_reply":"2022-01-09T18:36:25.795826Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"Here we define the collate function to apply after each batch generation: we simply create a dynamic padding since we sort by sequence lenght in the dataset. Then we proceed by padding the sequences to the maximum length found in the batch itself. This is useful in order to speed-up the BERT (and variants) processing.","metadata":{}},{"cell_type":"code","source":"def batch_padding(batch):\n    \n    max_len = max([len(sen['input_ids']) for sen in batch])\n    batch_padded_texts = []\n    batch_attention_mask = []\n    batch_target = []\n    \n    for b in batch:\n        l = len(b['input_ids'])\n        batch_padded_texts.append(b['input_ids'].tolist() + (max_len - l)*[0])\n        batch_attention_mask.append(b['attention_mask'].squeeze().tolist() + (max_len - l)*[0])\n        batch_target.append(b['target'])\n    \n    return {'input_ids': torch.tensor(batch_padded_texts), \n            'attention_mask': torch.tensor(batch_attention_mask) , \n            'target': torch.tensor(batch_target)}","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:36:25.798085Z","iopub.execute_input":"2022-01-09T18:36:25.798608Z","iopub.status.idle":"2022-01-09T18:36:25.810562Z","shell.execute_reply.started":"2022-01-09T18:36:25.798565Z","shell.execute_reply":"2022-01-09T18:36:25.809847Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"### Define the Model and DataLoader configurations","metadata":{}},{"cell_type":"code","source":"TRAIN_BATCH_SIZE = 200\nVALID_BATCH_SIZE = 100\nEPOCHS = 2\nDROPOUT_PROB = 0.3\nLR = 2e-5\nEPS = 1e-6\nWARMUP_STEPS = 0","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:36:25.811923Z","iopub.execute_input":"2022-01-09T18:36:25.812297Z","iopub.status.idle":"2022-01-09T18:36:25.823120Z","shell.execute_reply.started":"2022-01-09T18:36:25.812258Z","shell.execute_reply":"2022-01-09T18:36:25.822254Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Create the Dataloaders","metadata":{}},{"cell_type":"code","source":"trainDataLoader = DataLoader(trainDataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, pin_memory=True, collate_fn=batch_padding)\nvalidDataLoader = DataLoader(validDataset, batch_size=VALID_BATCH_SIZE, shuffle=False, pin_memory=True, collate_fn=batch_padding)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:36:25.826102Z","iopub.execute_input":"2022-01-09T18:36:25.826381Z","iopub.status.idle":"2022-01-09T18:36:25.832745Z","shell.execute_reply.started":"2022-01-09T18:36:25.826354Z","shell.execute_reply":"2022-01-09T18:36:25.831961Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    \n    def __init__(self, model='distilbert-base-uncased'):\n        super(CustomModel, self).__init__()\n        config = AutoConfig.from_pretrained(model)\n        self.model = AutoModel.from_pretrained(model, config=config)\n        self.dense = nn.Linear(self.model.config.dim, self.model.config.dim)\n        self.prediction = nn.Linear(self.model.config.dim, 1)\n        self.relu = nn.ReLU()\n        self.sigmoid = nn.Sigmoid()\n        self.dropout = nn.Dropout(DROPOUT_PROB)\n        \n    def forward(self, seq, attn_mask):\n        output = self.model(input_ids = seq, attention_mask = attn_mask)\n        output = output[0] #Take the hidden states of the last layer (batch_size, seq_len, hidden_dim)\n        output = output[:,0] #Take the hidden state returned by the CLS token\n#         output = self.dense(output)\n#         output = self.relu(output)\n        output = self.dropout(output)\n        output = self.prediction(output)\n        output = self.sigmoid(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:36:25.836143Z","iopub.execute_input":"2022-01-09T18:36:25.836446Z","iopub.status.idle":"2022-01-09T18:36:25.846276Z","shell.execute_reply.started":"2022-01-09T18:36:25.836381Z","shell.execute_reply":"2022-01-09T18:36:25.844689Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model = CustomModel().to(device)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:36:25.847468Z","iopub.execute_input":"2022-01-09T18:36:25.848172Z","iopub.status.idle":"2022-01-09T18:36:41.851813Z","shell.execute_reply.started":"2022-01-09T18:36:25.848123Z","shell.execute_reply":"2022-01-09T18:36:41.850880Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"#Training Loop\noptimizer = AdamW(model.parameters(), lr=LR, eps=EPS) # ALERT: this is the transformers library implementation one\nscheduler = get_linear_schedule_with_warmup(optimizer = optimizer,\n                                           num_warmup_steps = WARMUP_STEPS,\n                                           num_training_steps = EPOCHS*len(trainDataLoader))\nloss = nn.BCELoss().to(device)\n\ndef training_loop(trainDL, validDL, epochs, model, loss, optimizer, scheduler):\n    loss_history=[]\n    for epoch in tqdm(range(1,epochs+1), unit='epoch', desc='Epoch '):\n        training_loss = 0.0\n        mean_acc = 0.0\n        valid_loss = 0.0\n        mean_acc_valid = 0.0\n        for X in tqdm(trainDL, unit='batch', desc='Training progress batch: ', leave=False): #For each batch\n            y_pred = model(X['input_ids'].to(device), X['attention_mask'].to(device))\n            loss_pred = loss(y_pred, X['target'].unsqueeze(-1).to(device))\n            training_loss += loss_pred\n            acc = accuracy_score(torch.round(y_pred.detach().to(torch.device('cpu'))).int(), X['target'].int())\n            mean_acc += acc\n            loss_pred.backward()\n            optimizer.step()\n            scheduler.step()\n            optimizer.zero_grad()\n            del y_pred, loss_pred, acc\n            \n        model.eval() #Set evaluation mode for all the dropout and BN layers\n        \n        with torch.no_grad():\n            for V in tqdm(validDL, unit='batch', desc='Valid progress batch: ', leave=False):\n                y_valid_pred = model(V['input_ids'].to(device), \n                                     V['attention_mask'].to(device))\n                loss_valid_pred = loss(y_valid_pred, V['target'].unsqueeze(-1).to(device))\n                valid_loss += loss_valid_pred\n                acc_val = accuracy_score(torch.round(y_valid_pred.detach().to(torch.device('cpu'))).int(), V['target'].int())\n                mean_acc_valid += acc_val\n                del y_valid_pred, loss_valid_pred, acc_val\n                \n        model.train() #Reset the training switch\n        \n        mean_acc/=len(trainDL)    \n        training_loss/=len(trainDL)\n        valid_loss/=len(validDL)\n        mean_acc_valid/=len(validDL)\n        \n        print(f\"Epoch {epoch}:\")\n        print(f\"\\tTraining Loss {training_loss} - Accuracy {mean_acc}\")\n        print(f\"\\tValidation Loss {valid_loss} - Accuracy {mean_acc_valid}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:36:41.853326Z","iopub.execute_input":"2022-01-09T18:36:41.853694Z","iopub.status.idle":"2022-01-09T18:36:41.871094Z","shell.execute_reply.started":"2022-01-09T18:36:41.853656Z","shell.execute_reply":"2022-01-09T18:36:41.867964Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"training_loop(trainDataLoader,validDataLoader, EPOCHS, model, loss, optimizer, scheduler)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:36:41.872578Z","iopub.execute_input":"2022-01-09T18:36:41.873181Z","iopub.status.idle":"2022-01-09T19:24:09.563872Z","shell.execute_reply.started":"2022-01-09T18:36:41.873142Z","shell.execute_reply":"2022-01-09T19:24:09.562517Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T19:24:09.565329Z","iopub.execute_input":"2022-01-09T19:24:09.565696Z","iopub.status.idle":"2022-01-09T19:24:10.769688Z","shell.execute_reply.started":"2022-01-09T19:24:09.565658Z","shell.execute_reply":"2022-01-09T19:24:10.768512Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"y_test_pred = []\ny_test = []\n\nmodel.eval()\n\nfor x in tqdm(testDataset, desc='Evaluating test samples'):\n    y_test_pred.append(model(x['input_ids'].unsqueeze(0).to(device), x['attention_mask'].unsqueeze(0).to(device)).cpu())\n    y_test.append(x['target'])\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-09T19:52:45.365239Z","iopub.execute_input":"2022-01-09T19:52:45.365533Z","iopub.status.idle":"2022-01-09T19:52:45.431529Z","shell.execute_reply.started":"2022-01-09T19:52:45.365466Z","shell.execute_reply":"2022-01-09T19:52:45.430254Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}